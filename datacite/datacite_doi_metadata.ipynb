{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataCite Metadata Extraction for Digital Commons Batch Upload\n",
    "\n",
    "### What does this code do?\n",
    "\n",
    "This code searches using the DataCite API for datasets. It then downloads those metadata records and converts them into a format that can be used for a Digital Commons bulk upload, with appropriate headers. This file will be saved as an .xlsx file and will require manual re-saving to a .xls file for the actual upload. \n",
    "\n",
    "### Additional Manual Curation\n",
    "\n",
    "This file will also require manual curation before it is ready for upload, with special attention to:\n",
    "\n",
    "- Cleaning up affiliations, ex:\n",
    "  - Unifying names for a single institution: University of Alabama - Birmingham, UNIVERSITY OF ALABAMA AT BIRMINGHAM\n",
    "   &rarr; University of Alabama at Birmingham\n",
    "  - Un-abbreviating institution names: NYU &rarr; New York University \n",
    "  - Removing extraneous location details: California Digital Library, Oakland, United States of America &rarr; California Digital Library\n",
    "  - Ensuring there is only one affiliation per person (Digital Commons currently only allows a single affiliation)\n",
    "- Checking for names and keywords written in all caps\n",
    "- Checking for special characters or accents that are not formatted properly\n",
    "\n",
    "### What datasets are included?\n",
    "\n",
    "We want to include find datasets where at least one author is affiliated with the University if Alabama at Birmingham. We search requiring that the type of object is \"Dataset\" and using the UAB ROR in the affiliation-id. DataCite mints DOIs for several repositories, inclusing Dryad, Zenodo, and Figshare. It also may generate DOIs for other repositories.\n",
    "\n",
    "### Import the data as a json\n",
    "\n",
    "The code below uses a request url, `url_request`, to search using the DataCite API. To customize this, edit the URL to insert your own institution's. \n",
    "\n",
    "We are left with `results`, the API response in json format, which gets saved in the raw-data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results returned from API search:\n",
      "410\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "os.makedirs('raw-data', exist_ok=True)\n",
    "os.makedirs('batch-upload', exist_ok=True)\n",
    "\n",
    "ror_url = 'https://ror.org/008s83205' # edit this to change institution\n",
    "\n",
    "url_request =  'https://api.datacite.org/dois?affiliation-id=' + ror_url + '&resource-type-id=Dataset&affiliation=true&page[size]=1000'\n",
    "\n",
    "response = requests.get(url_request)\n",
    "if response.ok:\n",
    "  results = response.json()\n",
    "\n",
    "today = str(datetime.date.today())\n",
    "\n",
    "with open('raw-data/datacite_response' + today + '.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print('Results returned from API search:')\n",
    "print(len(results['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Reduction\n",
    "\n",
    "There are a few initial steps before we get into the proper reformatting of the records.\n",
    "\n",
    "1. Load the raw data from the json file and convert it to a Pandas dataframe.\n",
    "2. Save this dataframe as a csv (with the termination \"-full\") so we can view the raw data in a spreadsheet format.\n",
    "3. Remove Figshare duplicates. Figshare will often have multiple DOI versions that all lead to the same dataset, and are all individually returned by the DataCite API search. Therefore, we remove any figshare DOI that has a \".v\" in it, since the un-versioned original DOI will always point to the most recent version of the dataset.\n",
    "4. Remove datasets with excessive author lists. Digital Commons can accept up to 33 authors per entry. Any dataset with more than 33 authors is removed, but its DOI is noted in the \"long_list_names_[today].txt\" file. If Digital Commons changes their policy later, or you choose to include the full author list in another metadata field, you can have access to these datasets.\n",
    "   \n",
    "After performing these reductions, we are left with `df_input`, the dataframe we will use when we process and reformat the records. We save this as a .csv for easier inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "path = 'raw-data/datacite_response' + today + '.json'\n",
    "\n",
    "data = results\n",
    "df = pd.json_normalize(data[\"data\"], max_level = 1)\n",
    "\n",
    "df.to_csv('raw-data/raw-datacite'+today+'-full.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Remove multiple figshare duplicate versions (DOI+.v#)\n",
    "df = df[~df['id'].str.contains('figshare', case=False, na=False) | \n",
    "        ~df['id'].str.contains(r'\\.v', na=False)]\n",
    "\n",
    "# Filter names where the list column has more than 33 elements\n",
    "names = df.loc[df['attributes.creators'].apply(lambda x: len(x) > 33), 'id']\n",
    "\n",
    "# keep only under 33 names due to DC limit on author count\n",
    "\n",
    "df = df[df['attributes.creators'].apply(lambda x: len(x) <= 33)]\n",
    "\n",
    "# Write to a text file, one name per line\n",
    "with open('long_list_names_' + today + '.txt', 'w') as f:\n",
    "    for name in names:\n",
    "        f.write('https://doi.org/' + f\"{name}\\n\")\n",
    "\n",
    "df_input = df\n",
    "\n",
    "df.to_csv('raw-data/raw-datacite-'+today+'.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Functions defined below reshape the data from the initial spreadsheet/dataframe `df_input` and add columns to the dataframe df_output, which will later be exported and uploaded to Digital Commons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv \n",
    "\n",
    "def format_orcid(orcid):\n",
    "    if orcid[0] != 'h':\n",
    "        url_orcid = 'https://orcid.org/' + orcid\n",
    "        num_orcid = orcid\n",
    "    else:\n",
    "        url_orcid = orcid\n",
    "        num_orcid = orcid[18:]\n",
    "    return url_orcid, num_orcid\n",
    "\n",
    "def to_html(string):\n",
    "    '''Takes in a string. If the string is not in html already (assume first character is <) wrap it in <p> ... </p>.'''\n",
    "    if string[0] != \"<\":\n",
    "        string = \"<p>\" + string + \"</p>\"\n",
    "    return(string)\n",
    "\n",
    "def list_to_string(lst):\n",
    "    '''Takes in a list of strings ['a', 'b', 'c'] and returns a single string containing the list elements, separated by commas 'a, b, c'. '''\n",
    "    if isinstance(lst, list):  # Check if the value is a list\n",
    "        return ', '.join(lst)\n",
    "    else:\n",
    "        return \"\"  # Convert non-list values to string or handle as needed\n",
    "\n",
    "def csv_to_dict(file_path):\n",
    "    '''Imports data from a 2-column csv file, where the first column contains dictionary keys and the second column contains the corresponding values.\n",
    "    Outputs the resulting dictionary. Used with the relation_types.csv file to generate the strings used for the relation type of a related item.'''\n",
    "    result_dict = {}\n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            key = row[0]  # First column as key\n",
    "            value = row[1]  # Second column as value\n",
    "            result_dict[key] = value\n",
    "    return result_dict\n",
    "\n",
    "def get_titles(df1):\n",
    "    '''Generates titles column.'''\n",
    "    titles = []\n",
    "    for title_dict in df1['attributes.titles']:\n",
    "        title =  title_dict[0]['title']\n",
    "        titles.append(title)\n",
    "    df2 = pd.DataFrame(titles, columns = ['title'])\n",
    "    return df2   \n",
    "\n",
    "def add_orcid(df1, df2):\n",
    "    '''Finds authors with ORCIDs and lists them in html format for each dataset, along with hyperlinked urls.'''\n",
    "    orcid_pairs = [] # List for lists of author/orcid pairs where each element corresponds to a different dataset \n",
    "    for index, row in df1.iterrows():\n",
    "        pairs = [] # List for appending author/orcid pairs within one dataset\n",
    "        for author in row['attributes.creators']: # Iterate through the list of authors in each row of the metadata.creators column\n",
    "            #author = row['attributes.creators'][i]\n",
    "            if 'nameType' in author and author['nameType'] == 'Personal': # Check if author is a person\n",
    "                if 'nameIdentifiers' in author and len(author['nameIdentifiers']) > 0:  # Check if ORCID is present\n",
    "                    #orcid_url = make_url(author['nameIdentifiers'][0]['nameIdentifier'])\n",
    "                    orcid_url, orcid_num = format_orcid(author['nameIdentifiers'][0]['nameIdentifier'])\n",
    "                    first_last_name = author['givenName'] + ' ' + author['familyName']\n",
    "                    #pairs.append(orcid)\n",
    "                    #first_last_name = reformat_name(author['name'])\n",
    "                    pairs.append('<p>' + first_last_name + ' <a href=\"' + orcid_url + '\">' + orcid_num + '</a></p>')\n",
    "        orcid_pairs.append(\"\".join(pairs))  # Join multiple name-ORCID pairs with a comma\n",
    "    # Add this list as a new column in df2\n",
    "    df2['orcid'] = orcid_pairs\n",
    "    return df2    \n",
    "\n",
    "def add_pub_date(df1, df2):\n",
    "    '''Adds publication date column. Trims date to yyyy-mm-dd format. If only yyy exists, it uses that.'''\n",
    "    dates = []\n",
    "    for date_list in df1['attributes.dates']:\n",
    "        date_types = []\n",
    "        for date_type in date_list:\n",
    "            temp_date = date_type['date']\n",
    "\n",
    "            if len(temp_date) > 4:\n",
    "                date_types.append(temp_date[:10])\n",
    "        if len(date_types) == 0:\n",
    "            date_types.append(date_type['date'])\n",
    "        date = min(date_types)\n",
    "        dates.append(date)\n",
    "    df2['publication_date'] = dates\n",
    "    return df2\n",
    "\n",
    "def add_abstract(df1, df2):\n",
    "    '''Adds abstract column formatted in html.'''\n",
    "    abstracts = []\n",
    "    for description_dict in df1['attributes.descriptions']:\n",
    "        if len(description_dict) > 0:\n",
    "            abstract = to_html(description_dict[0]['description'])\n",
    "            abstracts.append(abstract)\n",
    "        else:\n",
    "            abstracts.append('')\n",
    "    df2['abstract'] = abstracts\n",
    "    return df2\n",
    "\n",
    "def add_keywords(df1, df2):\n",
    "    '''Adds keywords column in the format of a comma separated list'''\n",
    "    keywords = []\n",
    "    for keyword_list in df1['attributes.subjects']:\n",
    "        keyword_sublist = []\n",
    "        for word in keyword_list:\n",
    "            subject = word['subject']\n",
    "            keyword_sublist.append(subject)\n",
    "        keywords.append(list_to_string(keyword_sublist))\n",
    "    df2['keywords'] = keywords\n",
    "    return df2\n",
    "\n",
    "relation_dict = csv_to_dict('relation_types_datacite.csv')\n",
    "\n",
    "def add_related_items(df1, df2):\n",
    "    '''Adds related items from df1 to df2 with html formatting. Includes relation type taken from relation_dict dictionary. Formats PID appropriately if it is a DOI or other URL.'''\n",
    "    items = []\n",
    "    for index, row in df1.iterrows():\n",
    "        item = []\n",
    "        # Iterate through the related items if they are present\n",
    "        if isinstance(row['attributes.relatedIdentifiers'], list):\n",
    "            item.append('<p>')\n",
    "            count =0\n",
    "            for id in row['attributes.relatedIdentifiers']:\n",
    "                if pd.notnull(id):  \n",
    "                    if count > 0:\n",
    "                        item.append('<br>')\n",
    "                    count += 1\n",
    "                    if id['relationType']:\n",
    "                        item.append(relation_dict[id['relationType']] + ': ')\n",
    "                    if id['relatedIdentifierType'] == 'URL':\n",
    "                        url = id['relatedIdentifier']\n",
    "                        item.append( '<a href=\"'+ url + '\">' + url + '</a>')\n",
    "                    if id['relatedIdentifierType'] == 'DOI':\n",
    "                        doi = id['relatedIdentifier']\n",
    "                        item.append('<a href=\"https://doi.org/' + doi + '\">' + doi + '</a>')\n",
    "                    if id['relatedIdentifierType'] != 'URL' and id['relatedIdentifierType'] != 'DOI':\n",
    "                        item.append(id['relatedIdentifier'])\n",
    "            item.append('</p>')\n",
    "        else:\n",
    "            # If it's not a list put an empty cell\n",
    "            if pd.notnull(row['attributes.relatedIdentifiers']):\n",
    "                item.append('')\n",
    "        # Append the joined funder information to the list\n",
    "        items.append(\"\".join(item))\n",
    "    # Add the new 'fundref' column to df2\n",
    "    df2['related_data'] = items\n",
    "    return df2\n",
    "\n",
    "def add_funders(df1, df2):\n",
    "    '''Adds funder information from df1 to df2. Adds funder name, and optionally DOI, grant title, and grant number.'''\n",
    "    funders = []\n",
    "    for index, row in df1.iterrows():\n",
    "        funder = []\n",
    "        # Iterate through the grants if they are present\n",
    "        if isinstance(row['attributes.fundingReferences'], list):\n",
    "            for grant in row['attributes.fundingReferences']:\n",
    "                if pd.notnull(grant):  # Check if grant is not null\n",
    "                    funder.append('<p>Funder: ' + grant['funderName'])\n",
    "                    if 'funderIdentifierType' in grant and grant['funderIdentifierType'] == 'Crossref Funder ID':\n",
    "                        funder.append('<br>Funder DOI: <a href=\"https://doi.org/' + grant['funderIdentifier'] + '\">' +grant['funderIdentifier']+ '</a>')\n",
    "                    if 'funderIdentifierType' in grant and grant['funderIdentifierType'] == 'ROR':\n",
    "                        funder.append('<br>Funder ROR: <a href=\"' + grant['funderIdentifier'] + '\">' + grant['funderIdentifier'] + '</a>')\n",
    "                    if 'awardTitle' in grant:\n",
    "                        funder.append('<br>' + str(grant['awardTitle']))\n",
    "                    if 'awardNumber' in grant:\n",
    "                        funder.append('<br>' + grant['awardNumber'])\n",
    "                    funder.append('</p>')\n",
    "        else:\n",
    "            # If it's not a list put an empty cell\n",
    "            if pd.notnull(row['metadata.grants']):\n",
    "                funder.append('')\n",
    "        # Append the joined funder information to the list\n",
    "        funders.append(\"\".join(funder))\n",
    "    # Add the new 'fundref' column to df2\n",
    "    df2['fundref'] = funders\n",
    "    return df2\n",
    "\n",
    "\n",
    "\n",
    "def add_repository(df1, df2):\n",
    "    '''Adds publisher as repository. Note that for the figshare items added directly by publishers, the publisher will appear.\n",
    "    This is intentional so that these records may be inspected.'''\n",
    "    repositories = []\n",
    "    for repository in df1['attributes.publisher']:\n",
    "        repositories.append('<p>' + repository + '</p>')\n",
    "    df2['external_rep'] = repositories\n",
    "    return df2\n",
    "\n",
    "### Dictionary containing the DataCite terms for licenses (rightsIdentifier) as keys, with the values being a list containing the license URL as well as the html formatted text corresponding to each license.\n",
    "license_dict = {\"mit\" : [\"http://opensource.org/license/mit\", \"<p>This data is available under the MIT License</p>\"],\n",
    "                \"cc0-1.0\" : [\"http://creativecommons.org/public-domain/cc0/\", \"<p>This data is public domain under the CC-0.0 License</p>\"],\n",
    "                \"cc-by-4.0\" : [\"http://creativecommons.org/licenses/by/4.0/\", \"<p>This data is available under the CC-BY 4.0 License</p>\"],\n",
    "                \"cc-by-nc-nd-4.0\" : [\"http://creativecommons.org/licenses/by-nc-nd/4.0/\", \"<p>This data is available under the CC BY-NC-ND 4.0 License</p>\"],\n",
    "                \"cc-by-2.0\" : [\"http://creativecommons.org/licenses/by/2.0/\", \"<p>This data is available under the CC-BY 2.0 License</p>\"],\n",
    "                \"cc-by\" : [\"http://creativecommons.org/licenses/by/1.0/\", \"<p>This data is available under the CC-BY License</p>\"],\n",
    "                \"\" : [\"\", \"<p>Access to this data is restricted.</p>\"]\n",
    "}\n",
    "\n",
    "def add_license(df1, df2):\n",
    "    '''Adds licensing information columns to df2. Finds the value of the column metadata.license.id in df1\n",
    "    and uses it as a key for license_dict to retrieve the url fo the license and the string we want displayed in html.\n",
    "    If there is no value in that row, there is no license shown. We assume this means the data is restricted.'''\n",
    "    ids = []\n",
    "    for license_list in df1['attributes.rightsList']:\n",
    "        if len(license_list) > 0:\n",
    "            id = license_list[0]['rightsIdentifier']\n",
    "        else:\n",
    "            id = ''\n",
    "        ids.append(id)\n",
    "    licenses = [] # List for the license url\n",
    "    access = [] # List for the string/text explaining access\n",
    "    for id in ids:\n",
    "        #print(license_dict[id][0])\n",
    "        licenses.append(str(license_dict[id][0]))\n",
    "        access.append(str(license_dict[id][1]))\n",
    "    df2['distribution_license'] = licenses\n",
    "    df2['access_link'] = access\n",
    "    return df2\n",
    "\n",
    "def doi_link(df1, df2):\n",
    "    doi_links = []\n",
    "    for doi in df1['attributes.doi']:\n",
    "        doi_link = 'https://doi.org/' + doi\n",
    "        doi_links.append(doi_link)\n",
    "    df2['source_fulltext_url'] = doi_links\n",
    "    return df2\n",
    "\n",
    "def separate_name(name):\n",
    "    '''Separates a name into First, Middle (if applicable) and Last, returns these elements as separate strings.'''\n",
    "    middle = \"\"\n",
    "    \n",
    "    # Check if the name contains a comma (indicating \"last, first\" or \"last, first m.\" format)\n",
    "    if ',' in name:\n",
    "        parts = name.split(\", \") # Split into a list: \"last, first\" becomes [\"last\", \"first\"]\n",
    "        last = parts[0] # Last name is everything before the comma\n",
    "        \n",
    "        # Check if there's an element after the comma\n",
    "        if len(parts) > 1:\n",
    "            first_and_middle = parts[1].split() # Split whatever was after the comma with spaces\n",
    "            first = first_and_middle[0] # First name will be the first part of that\n",
    "            \n",
    "            # Assign middle if available\n",
    "            if len(first_and_middle) > 1: # If there is a second part\n",
    "                middle = first_and_middle[1].replace(\".\", \"\") # Assign middle name as second part, remove . because DC will add it\n",
    "        else:\n",
    "            # Set first to an empty string if there's nothing after the comma\n",
    "            first = \"\"\n",
    "    else: # If the name had no comma, you can assume it is in First Last or First Middle Last format\n",
    "        parts = name.split() # Split into a list where spaces are \n",
    "        \n",
    "        first = parts[0] # First name is first element of list\n",
    "        last = parts[-1] # Last name is the last element of the list \n",
    "        \n",
    "        # Check if there is a middle name/initial \n",
    "        if len(parts) > 2: \n",
    "            middle = parts[1].replace(\".\", \"\") # Remove period if it exists\n",
    "    \n",
    "    return first, middle, last\n",
    "\n",
    "def add_creators(df1, df2):\n",
    "    '''Adds creator information for author lists.\n",
    "    This function will make a new dataframe df3 and append it on to df2.'''\n",
    "    # Create a list to hold all rows of data for the new DataFrame\n",
    "    expanded_data = []\n",
    "    \n",
    "    # Process each row in df1\n",
    "    for _, row in df1.iterrows():\n",
    "        row_data = {}\n",
    "        creators = row['attributes.creators']\n",
    "        \n",
    "        # Populate the row_data dictionary with each author's name and affiliation\n",
    "        for i, creator in enumerate(creators):\n",
    "            author_index = i + 1\n",
    "            name = creator.get('name', \"\")\n",
    "            institution_info = creator.get('affiliation', \"\")  # Use 'institution' instead of 'affiliation' (DC nomenclature)\n",
    "            institutions = []\n",
    "            for inst in institution_info:\n",
    "                institutions.append(inst['name'])\n",
    "            \n",
    "            # Use the separate_name function to split names\n",
    "            first_name, middle_name, last_name = separate_name(name)\n",
    "            \n",
    "            # Assign names and institution to the row_data dictionary\n",
    "            row_data[f'author{author_index}_fname'] = first_name\n",
    "            row_data[f'author{author_index}_mname'] = middle_name\n",
    "            row_data[f'author{author_index}_lname'] = last_name\n",
    "            row_data[f'author{author_index}_institution'] = list_to_string(institutions)  # Change 'affl' to 'institution'\n",
    "        \n",
    "        # Append row_data dictionary to expanded_data list\n",
    "        expanded_data.append(row_data)\n",
    "\n",
    "    # Convert expanded_data list of dictionaries into a new DataFrame\n",
    "    df3 = pd.DataFrame(expanded_data)\n",
    "    \n",
    "    # Fill missing values with empty strings for any columns where data is missing\n",
    "    df3 = df3.fillna(\"\")\n",
    "    \n",
    "    df2_reset = df2.reset_index(drop=True)\n",
    "    df3_reset = df3.reset_index(drop=True)\n",
    "    \n",
    "    # Concatenate the two DataFrames along the columns\n",
    "    df_out = pd.concat([df2_reset, df3_reset], axis=1)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build output dataframe\n",
    "\n",
    "Calls the helper functions to build df_output, the dataframe which will them be exported as an Excel sheet.\n",
    "\n",
    "At this stage, de-duplication is performed. Sometimes, there will be multiple datasets with different DOIs but the same title - we assume these are different versions of the same dataset and keep only the most recent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>orcid</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>disciplines</th>\n",
       "      <th>source_publication</th>\n",
       "      <th>related_data</th>\n",
       "      <th>external_rep</th>\n",
       "      <th>distribution_license</th>\n",
       "      <th>...</th>\n",
       "      <th>author29_lname</th>\n",
       "      <th>author29_institution</th>\n",
       "      <th>author30_fname</th>\n",
       "      <th>author30_mname</th>\n",
       "      <th>author30_lname</th>\n",
       "      <th>author30_institution</th>\n",
       "      <th>author31_fname</th>\n",
       "      <th>author31_mname</th>\n",
       "      <th>author31_lname</th>\n",
       "      <th>author31_institution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Additional file 1 of Identifying and exploitin...</td>\n",
       "      <td></td>\n",
       "      <td>2025-06-29</td>\n",
       "      <td>&lt;p&gt;Supplementary Material 1: Table ST.1 Genes ...</td>\n",
       "      <td>Biochemistry, Medicine, Genetics, FOS: Biologi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Is supplement to: &lt;a href=\"https://doi.org/...</td>\n",
       "      <td>&lt;p&gt;figshare&lt;/p&gt;</td>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Additional file 2 of The sustainability of hea...</td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>&lt;p&gt;Supplementary Material 2.&lt;/p&gt;</td>\n",
       "      <td>Medicine, Biotechnology, Sociology, FOS: Socio...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Is supplement to: &lt;a href=\"https://doi.org/...</td>\n",
       "      <td>&lt;p&gt;figshare&lt;/p&gt;</td>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Additional file 7 of Identifying differentiati...</td>\n",
       "      <td></td>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>&lt;p&gt;Supplementary Material 7&lt;/p&gt;</td>\n",
       "      <td>Genetics, FOS: Biological sciences</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Is supplement to: &lt;a href=\"https://doi.org/...</td>\n",
       "      <td>&lt;p&gt;figshare&lt;/p&gt;</td>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Additional file 6 of Identifying differentiati...</td>\n",
       "      <td></td>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>&lt;p&gt;Supplementary Material 6&lt;/p&gt;</td>\n",
       "      <td>Genetics, FOS: Biological sciences</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Is supplement to: &lt;a href=\"https://doi.org/...</td>\n",
       "      <td>&lt;p&gt;figshare&lt;/p&gt;</td>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Additional file 5 of Identifying differentiati...</td>\n",
       "      <td></td>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>&lt;p&gt;Supplementary Material 5&lt;/p&gt;</td>\n",
       "      <td>Genetics, FOS: Biological sciences</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Is supplement to: &lt;a href=\"https://doi.org/...</td>\n",
       "      <td>&lt;p&gt;figshare&lt;/p&gt;</td>\n",
       "      <td>http://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cystic fibrosis autoantibody signatures associ...</td>\n",
       "      <td>&lt;p&gt;Balazs Rada &lt;a href=\"https://orcid.org/0000...</td>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>&lt;p&gt;While cystic fibrosis (CF) lung disease is ...</td>\n",
       "      <td>FOS: Biological sciences, FOS: Biological scie...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Is cited by: &lt;a href=\"https://doi.org/10.33...</td>\n",
       "      <td>&lt;p&gt;Dryad&lt;/p&gt;</td>\n",
       "      <td>http://creativecommons.org/public-domain/cc0/</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Data from: Evolutionary history of chimpanzees...</td>\n",
       "      <td></td>\n",
       "      <td>2010-08-19</td>\n",
       "      <td>&lt;p&gt;Investigations into the evolutionary histor...</td>\n",
       "      <td>chimpanzee, Pan troglodytes, relaxed molecular...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Is cited by: &lt;a href=\"https://doi.org/10.10...</td>\n",
       "      <td>&lt;p&gt;Dryad&lt;/p&gt;</td>\n",
       "      <td>http://creativecommons.org/public-domain/cc0/</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Data from: Female investment in offspring size...</td>\n",
       "      <td></td>\n",
       "      <td>2018-04-19</td>\n",
       "      <td>&lt;p&gt;The timing of reproduction strongly influen...</td>\n",
       "      <td>tradeoffs, Reproducibility, Anolis sagrei, par...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Is cited by: &lt;a href=\"https://doi.org/10.10...</td>\n",
       "      <td>&lt;p&gt;Dryad&lt;/p&gt;</td>\n",
       "      <td>http://creativecommons.org/public-domain/cc0/</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Market forces determine the distribution of a ...</td>\n",
       "      <td>&lt;p&gt;Jeffrey Morris &lt;a href=\"https://orcid.org/0...</td>\n",
       "      <td>2021-09-08</td>\n",
       "      <td>&lt;p&gt;Many biological functions are leaky, and or...</td>\n",
       "      <td>FOS: Biological sciences, FOS: Biological scie...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Is derived from: &lt;a href=\"https://doi.org/1...</td>\n",
       "      <td>&lt;p&gt;Dryad&lt;/p&gt;</td>\n",
       "      <td>http://creativecommons.org/public-domain/cc0/</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Predicting and Preventing Neglect in Teen Moth...</td>\n",
       "      <td>&lt;p&gt;Kristi Guest &lt;a href=\"https://orcid.org/000...</td>\n",
       "      <td>2011</td>\n",
       "      <td>&lt;p&gt;The ‘Predicting And Preventing Child Neglec...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>&lt;p&gt;National Data Archive on Child Abuse and Ne...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "53   Additional file 1 of Identifying and exploitin...   \n",
       "62   Additional file 2 of The sustainability of hea...   \n",
       "67   Additional file 7 of Identifying differentiati...   \n",
       "69   Additional file 6 of Identifying differentiati...   \n",
       "68   Additional file 5 of Identifying differentiati...   \n",
       "..                                                 ...   \n",
       "13   Cystic fibrosis autoantibody signatures associ...   \n",
       "48   Data from: Evolutionary history of chimpanzees...   \n",
       "44   Data from: Female investment in offspring size...   \n",
       "20   Market forces determine the distribution of a ...   \n",
       "215  Predicting and Preventing Neglect in Teen Moth...   \n",
       "\n",
       "                                                 orcid publication_date  \\\n",
       "53                                                           2025-06-29   \n",
       "62                                                           2025-04-09   \n",
       "67                                                           2025-02-12   \n",
       "69                                                           2025-02-12   \n",
       "68                                                           2025-02-12   \n",
       "..                                                 ...              ...   \n",
       "13   <p>Balazs Rada <a href=\"https://orcid.org/0000...       2023-08-03   \n",
       "48                                                           2010-08-19   \n",
       "44                                                           2018-04-19   \n",
       "20   <p>Jeffrey Morris <a href=\"https://orcid.org/0...       2021-09-08   \n",
       "215  <p>Kristi Guest <a href=\"https://orcid.org/000...             2011   \n",
       "\n",
       "                                              abstract  \\\n",
       "53   <p>Supplementary Material 1: Table ST.1 Genes ...   \n",
       "62                    <p>Supplementary Material 2.</p>   \n",
       "67                     <p>Supplementary Material 7</p>   \n",
       "69                     <p>Supplementary Material 6</p>   \n",
       "68                     <p>Supplementary Material 5</p>   \n",
       "..                                                 ...   \n",
       "13   <p>While cystic fibrosis (CF) lung disease is ...   \n",
       "48   <p>Investigations into the evolutionary histor...   \n",
       "44   <p>The timing of reproduction strongly influen...   \n",
       "20   <p>Many biological functions are leaky, and or...   \n",
       "215  <p>The ‘Predicting And Preventing Child Neglec...   \n",
       "\n",
       "                                              keywords disciplines  \\\n",
       "53   Biochemistry, Medicine, Genetics, FOS: Biologi...               \n",
       "62   Medicine, Biotechnology, Sociology, FOS: Socio...               \n",
       "67                  Genetics, FOS: Biological sciences               \n",
       "69                  Genetics, FOS: Biological sciences               \n",
       "68                  Genetics, FOS: Biological sciences               \n",
       "..                                                 ...         ...   \n",
       "13   FOS: Biological sciences, FOS: Biological scie...               \n",
       "48   chimpanzee, Pan troglodytes, relaxed molecular...               \n",
       "44   tradeoffs, Reproducibility, Anolis sagrei, par...               \n",
       "20   FOS: Biological sciences, FOS: Biological scie...               \n",
       "215                                                                  \n",
       "\n",
       "    source_publication                                       related_data  \\\n",
       "53                      <p>Is supplement to: <a href=\"https://doi.org/...   \n",
       "62                      <p>Is supplement to: <a href=\"https://doi.org/...   \n",
       "67                      <p>Is supplement to: <a href=\"https://doi.org/...   \n",
       "69                      <p>Is supplement to: <a href=\"https://doi.org/...   \n",
       "68                      <p>Is supplement to: <a href=\"https://doi.org/...   \n",
       "..                 ...                                                ...   \n",
       "13                      <p>Is cited by: <a href=\"https://doi.org/10.33...   \n",
       "48                      <p>Is cited by: <a href=\"https://doi.org/10.10...   \n",
       "44                      <p>Is cited by: <a href=\"https://doi.org/10.10...   \n",
       "20                      <p>Is derived from: <a href=\"https://doi.org/1...   \n",
       "215                                                               <p></p>   \n",
       "\n",
       "                                          external_rep  \\\n",
       "53                                     <p>figshare</p>   \n",
       "62                                     <p>figshare</p>   \n",
       "67                                     <p>figshare</p>   \n",
       "69                                     <p>figshare</p>   \n",
       "68                                     <p>figshare</p>   \n",
       "..                                                 ...   \n",
       "13                                        <p>Dryad</p>   \n",
       "48                                        <p>Dryad</p>   \n",
       "44                                        <p>Dryad</p>   \n",
       "20                                        <p>Dryad</p>   \n",
       "215  <p>National Data Archive on Child Abuse and Ne...   \n",
       "\n",
       "                              distribution_license  ... author29_lname  \\\n",
       "53     http://creativecommons.org/licenses/by/4.0/  ...                  \n",
       "62     http://creativecommons.org/licenses/by/4.0/  ...                  \n",
       "67     http://creativecommons.org/licenses/by/4.0/  ...                  \n",
       "69     http://creativecommons.org/licenses/by/4.0/  ...                  \n",
       "68     http://creativecommons.org/licenses/by/4.0/  ...                  \n",
       "..                                             ...  ...            ...   \n",
       "13   http://creativecommons.org/public-domain/cc0/  ...                  \n",
       "48   http://creativecommons.org/public-domain/cc0/  ...                  \n",
       "44   http://creativecommons.org/public-domain/cc0/  ...                  \n",
       "20   http://creativecommons.org/public-domain/cc0/  ...                  \n",
       "215                                                 ...                  \n",
       "\n",
       "    author29_institution author30_fname author30_mname author30_lname  \\\n",
       "53                                                                      \n",
       "62                                                                      \n",
       "67                                                                      \n",
       "69                                                                      \n",
       "68                                                                      \n",
       "..                   ...            ...            ...            ...   \n",
       "13                                                                      \n",
       "48                                                                      \n",
       "44                                                                      \n",
       "20                                                                      \n",
       "215                                                                     \n",
       "\n",
       "    author30_institution author31_fname author31_mname author31_lname  \\\n",
       "53                                                                      \n",
       "62                                                                      \n",
       "67                                                                      \n",
       "69                                                                      \n",
       "68                                                                      \n",
       "..                   ...            ...            ...            ...   \n",
       "13                                                                      \n",
       "48                                                                      \n",
       "44                                                                      \n",
       "20                                                                      \n",
       "215                                                                     \n",
       "\n",
       "    author31_institution  \n",
       "53                        \n",
       "62                        \n",
       "67                        \n",
       "69                        \n",
       "68                        \n",
       "..                   ...  \n",
       "13                        \n",
       "48                        \n",
       "44                        \n",
       "20                        \n",
       "215                       \n",
       "\n",
       "[186 rows x 137 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title\n",
    "df_output = get_titles(df_input)\n",
    "\n",
    "# orcid\n",
    "df_output = add_orcid(df_input, df_output)\n",
    "\n",
    "# publication_date\n",
    "df_output = add_pub_date(df_input, df_output)\n",
    "\n",
    "# abstract\n",
    "df_output = add_abstract(df_input, df_output)\n",
    "\n",
    "# keywords\n",
    "df_output = add_keywords(df_input, df_output)\n",
    "\n",
    "# disciplines\n",
    "df_output[\"disciplines\"] = \"\" #make blank column, we will need to fill in the values\n",
    "\n",
    "#source_publication\n",
    "df_output[\"source_publication\"] = \"\" #make blank column, we will need to fill in the values\n",
    "\n",
    "# related_data\n",
    "df_output = add_related_items(df1=df_input, df2=df_output)\n",
    "\n",
    "\n",
    "# external_rep\n",
    "df_output = add_repository(df_input, df_output)\n",
    "\n",
    "# license\n",
    "df_output = add_license(df_input, df_output)\n",
    "\n",
    "\n",
    "# funder_info\n",
    "df_output = add_funders(df1=df_input, df2=df_output)\n",
    "\n",
    "# source_fulltext_url\n",
    "df_output = doi_link(df_input, df_output)\n",
    "\n",
    "# author info (<30)\n",
    "df_output = add_creators(df1=df_input, df2=df_output)\n",
    "\n",
    "# Remove entries with the same title, keeping the more recent DOI\n",
    "\n",
    "# Sort by title and DOI (alphabetically)\n",
    "df_sorted = df_output.sort_values(by=['title', 'source_fulltext_url'], ascending=[True, True])\n",
    "\n",
    "# Drop duplicates, keeping the first (which now has the smallest DOI)\n",
    "df_deduped = df_sorted.drop_duplicates(subset='title', keep='first')\n",
    "\n",
    "df_out = df_deduped.sort_values(by='source_fulltext_url', ascending=False)\n",
    "\n",
    "df_out.to_excel('batch-upload/datacite_batch_upload' + today + '.xlsx', index=False)\n",
    "\n",
    "df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenodo-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
