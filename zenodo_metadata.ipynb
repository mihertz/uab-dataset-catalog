{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zenodo Metadata Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "ACCESS_TOKEN = '5lRvVDSnCTTXgdFWLuCN7HLAK2UWKjUbJwPCEiWJxirzVT3VfLsAeHnhflmt'\n",
    "search_query = 'creators.affiliation:(+university +alabama +birmingham)'\n",
    "\n",
    "response = requests.get('https://zenodo.org/api/records/',\n",
    "                        params={'q': search_query,\n",
    "                                'access_token': ACCESS_TOKEN,\n",
    "                                'size': 200, # should be 128, add headroom\n",
    "                                'type' : 'dataset'\n",
    "                                })\n",
    "\n",
    "records = response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the necessary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### MAKE THE DATAFRAME\n",
    "df = pd.json_normalize(records['hits']['hits'][0])\n",
    "for i in range(1, len(records['hits']['hits'])):\n",
    "    df_row = pd.json_normalize(records['hits']['hits'][i])\n",
    "    # df_row = df_row.drop(columns = ['stats'])\n",
    "\n",
    "    df = pd.concat([df, df_row])\n",
    "\n",
    "### DROP UNWANTED COLUMNS\n",
    "\n",
    "unwanted_cols = ['conceptrecid', 'recid', 'revision', 'files', 'owners', 'status', 'state', 'submitted', 'metadata.title', 'metadata.resource_type.title', \n",
    "                 'metadata.resource_type.type', 'metadata.communities', 'metadata.relations.version', 'links.self', 'links.doi', 'links.self_doi', 'links.self_doi_html', \n",
    "                 'links.parent', 'links.self_iiif_manifest', 'links.self_iiif_sequence', 'links.files', 'links.media_files', 'links.archive', 'links.archive_media', \n",
    "                 'links.latest', 'links.latest_html', 'links.versions', 'links.draft', 'links.reserve_doi', 'links.access_links', 'links.access_grants', 'links.access_users',\n",
    "                 'links.access_request', 'links.access', 'links.communities', 'links.communities-suggestions', 'links.requests', 'stats.downloads', 'stats.unique_downloads',\n",
    "                 'stats.views', 'stats.unique_views', 'stats.version_downloads', 'stats.version_unique_downloads', 'stats.version_unique_views', 'stats.version_views'\n",
    "                ]\n",
    "\n",
    "df = df.drop(columns=unwanted_cols)\n",
    "\n",
    "df_input = df\n",
    "# df_input = expand_creators(df)\n",
    "# df_input = expand_columns(df, col_name = 'metadata.creators', fields = ['name', 'affiliation', 'orcid'])\n",
    "#df_input = expand_columns(df_input, col_name = 'metadata.related_identifiers', fields = ['identifier', 'relation'])\n",
    "#df_input = expand_columns(df_input, col_name = 'metadata.grants', fields = ['code', 'title', 'funder'])\n",
    "\n",
    "df_input.to_csv('zenodo_expanded_raw.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "import csv\n",
    "\n",
    "def csv_to_dict(file_path):\n",
    "    result_dict = {}\n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            key = row[0]  # First column as key\n",
    "            value = row[1]  # Second column as value\n",
    "            result_dict[key] = value\n",
    "    return result_dict\n",
    "\n",
    "def expand_columns(df1, col_name, fields, df2):\n",
    "    df1[col_name] = df1[col_name].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "    # Find the maximum number of dictionaries in any row\n",
    "    max_dicts = df1[col_name].apply(len).max()\n",
    "\n",
    "    # Iterate over the possible dictionary positions (1 to max_dicts)\n",
    "    for i in range(max_dicts):\n",
    "        for field in fields:\n",
    "            # Create new column names dynamically\n",
    "            new_col = f'{field}_{i+1}'\n",
    "            \n",
    "            # Extract the i-th dictionary's field data if it exists, otherwise set None\n",
    "            df2[new_col] = df1[col_name].apply(lambda x: x[i].get(field) if i < len(x) else None)\n",
    "    return df2\n",
    "\n",
    "def add_col(df1, col1name, df2, col2name):\n",
    "    # takes col1 out of df1 and adds it onto df2 with new name \n",
    "    extracted_col = df1[col1name]\n",
    "    df2 = pd.concat([df2, extracted_col.rename(col2name)], axis=1)\n",
    "    return df2\n",
    "\n",
    "def list_to_string(lst):\n",
    "    if isinstance(lst, list):  # Check if the value is a list\n",
    "        return ', '.join(lst)\n",
    "    else:\n",
    "        return \"\"  # Convert non-list values to string or handle as needed\n",
    "\n",
    "def url_to_html(url, link_text=None):\n",
    "    if not url:\n",
    "        return ''  # Return empty string if no URL is provided\n",
    "    link_text = link_text or url  # Use the URL as the link text if no text is provided\n",
    "    return f'<a href=\"{url}\">{link_text}</a>'\n",
    "\n",
    "license_dict = {\"mit-license\" : [\"https://opensource.org/license/mit\", \"<p>This data is available under the MIT License</p>\"],\n",
    "                \"cc-zero\" : [\"https://creativecommons.org/public-domain/cc0/\", \"<p>This data is public domain under the CC-0.0 License</p>\"],\n",
    "                \"cc-by-4.0\" : [\"http://creativecommons.org/licenses/by/4.0/\", \"<p>This data is available under the CC-BY 4.0 License</p>\"],\n",
    "                \"cc-by-2.0\" : [\"http://creativecommons.org/licenses/by/2.0/\", \"<p>This data is available under the CC-BY 2.0 License</p>\"],\n",
    "                \"cc-by\" : [\"https://creativecommons.org/licenses/by/1.0/\", \"<p>This data is available under the CC-BY License</p>\"]\n",
    "}\n",
    "\n",
    "def add_license(df1, df2):\n",
    "    licenses = []\n",
    "    access = []\n",
    "    for license in df1['metadata.license.id']:\n",
    "        if pd.notnull(license):\n",
    "            licenses.append(license_dict[license][0])\n",
    "            access.append(license_dict[license][1])\n",
    "        else:\n",
    "            licenses.append('')\n",
    "            access.append('<p>Access to this data is restricted.</p>')\n",
    "    df2['distribution_license'] = licenses\n",
    "    df2['access_link'] = access\n",
    "    return df2\n",
    "\n",
    "def separate_name(name):\n",
    "    # Initialize middle as an empty string\n",
    "    middle = \"\"\n",
    "    \n",
    "    # Check if the name contains a comma (indicating \"last, first\" or \"last, first m.\" format)\n",
    "    if ',' in name:\n",
    "        parts = name.split(\", \")\n",
    "        last = parts[0]\n",
    "        \n",
    "        # Check if there's a second element after the comma\n",
    "        if len(parts) > 1:\n",
    "            first_and_middle = parts[1].split()\n",
    "            first = first_and_middle[0]\n",
    "            \n",
    "            # Assign middle if available\n",
    "            if len(first_and_middle) > 1:\n",
    "                middle = first_and_middle[1]\n",
    "        else:\n",
    "            # Set first to an empty string if there's nothing after the comma\n",
    "            first = \"\"\n",
    "    else:\n",
    "        # Assume \"first last\" or \"first m. last\" format\n",
    "        parts = name.split()\n",
    "        \n",
    "        first = parts[0]\n",
    "        last = parts[-1]\n",
    "        \n",
    "        # Check if there is a middle name/initial\n",
    "        if len(parts) > 2:\n",
    "            middle = parts[1]\n",
    "\n",
    "    return first, middle, last\n",
    "    \n",
    "def reformat_name(name):\n",
    "    # Check if the name contains a comma\n",
    "    if ', ' in name:\n",
    "        # Split the string by comma and strip any extra whitespace\n",
    "        last, first = name.split(\", \")\n",
    "        # Return the string in \"first last\" format\n",
    "        return f\"{first} {last}\"\n",
    "    else:\n",
    "        # Return the name unchanged if there's no comma\n",
    "        return name\n",
    "    \n",
    "def add_orcid(df1, df2):\n",
    "    orcid_pairs = []\n",
    "    for index, row in df1.iterrows():\n",
    "        pairs = []\n",
    "        for author in row['metadata.creators']:\n",
    "            if 'orcid' in author:  # Check if ORCID is present\n",
    "                first_last_name = reformat_name(author['name'])\n",
    "                pairs.append('<p>' + first_last_name + '<a href=\"https://orcid.org/' + author['orcid'] + '\">' +author['orcid']+ '</a></p>')\n",
    "        orcid_pairs.append(\"\".join(pairs))  # Join multiple name-ORCID pairs with a comma\n",
    "    # Add this list as a new column in df2\n",
    "    df2['orcid'] = orcid_pairs\n",
    "    return df2\n",
    "\n",
    "def to_html(string):\n",
    "    if string[0] != \"<\":\n",
    "        string = \"<p>\" + string + \"</p>\"\n",
    "    return(string)\n",
    "\n",
    "def add_funders(df1, df2):\n",
    "    funders = []\n",
    "    count = 0\n",
    "    for index, row in df1.iterrows():\n",
    "        funder = []\n",
    "        # Iterate through the grants if they are present\n",
    "        if isinstance(row['metadata.grants'], list):\n",
    "            for grant in row['metadata.grants']:\n",
    "                if pd.notnull(grant):  # Check if grant is not null\n",
    "                    funder.append('<p>Funder: ' + grant['funder']['name'])\n",
    "                    if 'doi' in grant['funder']:\n",
    "                        funder.append('<br>Funder DOI: <a href=\"https://doi.org/' + grant['funder']['doi'] + '\">' +grant['funder']['doi']+ '</a>')\n",
    "                    if 'title' in grant:\n",
    "                        funder.append('<br>' + grant['title'])\n",
    "                    if 'code' in grant:\n",
    "                        funder.append('<br>' + grant['code'])\n",
    "                    funder.append('</p>')\n",
    "        else:\n",
    "            # If it's not a list put an empty cell\n",
    "            if pd.notnull(row['metadata.grants']):\n",
    "                funder.append('')\n",
    "        # Append the joined funder information to the list\n",
    "        funders.append(\"\".join(funder))\n",
    "    # Add the new 'fundref' column to df2\n",
    "    df2['fundref'] = funders\n",
    "    return df2\n",
    "\n",
    "def add_related_items(df1, df2):\n",
    "    items = []\n",
    "    count = 0\n",
    "    for index, row in df1.iterrows():\n",
    "        item = []\n",
    "        # Iterate through the grants if they are present\n",
    "        if isinstance(row['metadata.related_identifiers'], list):\n",
    "            for id in row['metadata.related_identifiers']:\n",
    "                if pd.notnull(id):  \n",
    "                    item.append('<p>' + id['identifier'])\n",
    "\n",
    "                    if id['relation']:\n",
    "                        item.append('<br>' + id['relation'])\n",
    "                    item.append('</p>')\n",
    "        else:\n",
    "            # If it's not a list put an empty cell\n",
    "            if pd.notnull(row['metadata.related_identifiers']):\n",
    "                item.append('')\n",
    "        # Append the joined funder information to the list\n",
    "        items.append(\"\".join(item))\n",
    "    # Add the new 'fundref' column to df2\n",
    "    df2['related_data'] = items\n",
    "    return df2\n",
    "\n",
    "def add_creators(df1, df2):\n",
    "    # Find the maximum number of authors across all rows in 'metadata.creators'\n",
    "    max_authors = df1['metadata.creators'].apply(len).max()\n",
    "\n",
    "    # Create a list to hold all rows of data for the new DataFrame\n",
    "    expanded_data = []\n",
    "    \n",
    "    # Process each row in df1\n",
    "    for _, row in df1.iterrows():\n",
    "        row_data = {}\n",
    "        creators = row['metadata.creators']\n",
    "        \n",
    "        # Populate the row_data dictionary with each author's name and affiliation\n",
    "        for i, creator in enumerate(creators):\n",
    "            author_index = i + 1\n",
    "            name = creator.get('name', \"\")\n",
    "            institution = creator.get('affiliation', \"\")  # Use 'institution' instead of 'affiliation'\n",
    "            \n",
    "            # Use the separate_name function to split names\n",
    "            first_name, middle_name, last_name = separate_name(name)\n",
    "            \n",
    "            # Assign names and institution to the row_data dictionary\n",
    "            row_data[f'author{author_index}_fname'] = first_name\n",
    "            row_data[f'author{author_index}_mname'] = middle_name\n",
    "            row_data[f'author{author_index}_lname'] = last_name\n",
    "            row_data[f'author{author_index}_institution'] = institution  # Change 'affl' to 'institution'\n",
    "        \n",
    "        # Append row_data dictionary to expanded_data list\n",
    "        expanded_data.append(row_data)\n",
    "\n",
    "    # Convert expanded_data list of dictionaries into a new DataFrame\n",
    "    df3 = pd.DataFrame(expanded_data)\n",
    "    \n",
    "    # Fill missing values with empty strings for any columns where data is missing\n",
    "    df3 = df3.fillna(\"\")\n",
    "    \n",
    "    df2_reset = df2.reset_index(drop=True)\n",
    "    df3_reset = df3.reset_index(drop=True)\n",
    "    \n",
    "    # Concatenate the two DataFrames along the columns\n",
    "    df_out = pd.concat([df2_reset, df3_reset], axis=1)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build output dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Claire\\AppData\\Local\\Temp\\ipykernel_57024\\2511423357.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['orcid'] = orcid_pairs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>orcid</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>disciplines</th>\n",
       "      <th>source_publication</th>\n",
       "      <th>related_data</th>\n",
       "      <th>source_fulltext_url</th>\n",
       "      <th>external_rep</th>\n",
       "      <th>...</th>\n",
       "      <th>author47_lname</th>\n",
       "      <th>author47_institution</th>\n",
       "      <th>author48_fname</th>\n",
       "      <th>author48_mname</th>\n",
       "      <th>author48_lname</th>\n",
       "      <th>author48_institution</th>\n",
       "      <th>author49_fname</th>\n",
       "      <th>author49_mname</th>\n",
       "      <th>author49_lname</th>\n",
       "      <th>author49_institution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alzheimer's disease risk gene BIN1 induces Tau...</td>\n",
       "      <td>&lt;p&gt;Yuliya Voskobiynyk&lt;a href=\"https://orcid.or...</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>&lt;p&gt;Genome-wide association studies identified ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;10.7554/eLife.57354&lt;/p&gt;</td>\n",
       "      <td>https://doi.org/10.5061/dryad.rbnzs7h8z</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data from: The effect of Speed of Processing t...</td>\n",
       "      <td></td>\n",
       "      <td>2015-08-04</td>\n",
       "      <td>&lt;p&gt;Older adults experience cognitive deficits ...</td>\n",
       "      <td>peripheral, Useful Field of View, cognitive in...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;10.1371/journal.pone.0107808&lt;/p&gt;</td>\n",
       "      <td>https://doi.org/10.5061/dryad.4fn70</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data for Cell-type-specific alternative splici...</td>\n",
       "      <td>&lt;p&gt;Emma F. Jones&lt;a href=\"https://orcid.org/000...</td>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>&lt;p&gt;&lt;span&gt;&lt;strong&gt;data.tar.gz &lt;/strong&gt;contains...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;10.5281/zenodo.12548384&lt;/p&gt;&lt;p&gt;10.5281/zenod...</td>\n",
       "      <td>https://doi.org/10.5281/zenodo.12535061</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data for Long-read RNA sequencing identifies r...</td>\n",
       "      <td>&lt;p&gt;Emma F. Jones&lt;a href=\"https://orcid.org/000...</td>\n",
       "      <td>2023-12-14</td>\n",
       "      <td>&lt;p&gt;&lt;span&gt;data_minus_bam.tar.gz contains all fi...</td>\n",
       "      <td>long-read RNA sequencing, brain, sex, alternat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;https://github.com/lasseignelab/230227_EJ_M...</td>\n",
       "      <td>https://doi.org/10.5281/zenodo.10381745</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data for Altered Glia-Neuron Communication in ...</td>\n",
       "      <td>&lt;p&gt;Tabea Soelter&lt;a href=\"https://orcid.org/000...</td>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;data.tar.gz contains all files from...</td>\n",
       "      <td>Alzheimer's disease, neurodegeneration, cell-c...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;10.5281/zenodo.10211623&lt;/p&gt;</td>\n",
       "      <td>https://doi.org/10.5281/zenodo.10214497</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Dataset for \"What is Gab? A Bastion of Free Sp...</td>\n",
       "      <td></td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>&lt;p&gt;This dataset was used for this project: &amp;qu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://doi.org/10.5281/zenodo.3460400</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Public Dataset for \"Large Scale Crowdsourcing ...</td>\n",
       "      <td></td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>&lt;p&gt;Dataset for the &amp;quot;Large Scale Crowdsour...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://doi.org/10.5281/zenodo.3678559</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Transposon DNA sequences facilitate the tissue...</td>\n",
       "      <td></td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>&lt;p&gt;The uploaded files are in the&amp;nbsp;fasta fo...</td>\n",
       "      <td>Horizontal gene transfer, circulating tumor DN...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://doi.org/10.5281/zenodo.7958520</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Functional connectivity in the face of congeni...</td>\n",
       "      <td>&lt;p&gt;Pinar Demirayak&lt;a href=\"https://orcid.org/0...</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>&lt;p&gt;Results of diffusion tensor imaging analysi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://doi.org/10.5281/zenodo.3401600</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>CORTICAL CONNECTIVITY IN THE FACE OF CONGENITA...</td>\n",
       "      <td>&lt;p&gt;Pinar Demirayak&lt;a href=\"https://orcid.org/0...</td>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>&lt;p&gt;Results of structural and functional connec...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://doi.org/10.5281/zenodo.4598198</td>\n",
       "      <td>&lt;p&gt;Zenodo&lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows Ã— 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Alzheimer's disease risk gene BIN1 induces Tau...   \n",
       "1    Data from: The effect of Speed of Processing t...   \n",
       "2    Data for Cell-type-specific alternative splici...   \n",
       "3    Data for Long-read RNA sequencing identifies r...   \n",
       "4    Data for Altered Glia-Neuron Communication in ...   \n",
       "..                                                 ...   \n",
       "124  Dataset for \"What is Gab? A Bastion of Free Sp...   \n",
       "125  Public Dataset for \"Large Scale Crowdsourcing ...   \n",
       "126  Transposon DNA sequences facilitate the tissue...   \n",
       "127  Functional connectivity in the face of congeni...   \n",
       "128  CORTICAL CONNECTIVITY IN THE FACE OF CONGENITA...   \n",
       "\n",
       "                                                 orcid publication_date  \\\n",
       "0    <p>Yuliya Voskobiynyk<a href=\"https://orcid.or...       2020-08-19   \n",
       "1                                                            2015-08-04   \n",
       "2    <p>Emma F. Jones<a href=\"https://orcid.org/000...       2024-06-25   \n",
       "3    <p>Emma F. Jones<a href=\"https://orcid.org/000...       2023-12-14   \n",
       "4    <p>Tabea Soelter<a href=\"https://orcid.org/000...       2023-11-28   \n",
       "..                                                 ...              ...   \n",
       "124                                                          2018-09-13   \n",
       "125                                                          2020-02-21   \n",
       "126                                                          2023-05-24   \n",
       "127  <p>Pinar Demirayak<a href=\"https://orcid.org/0...       2019-09-06   \n",
       "128  <p>Pinar Demirayak<a href=\"https://orcid.org/0...       2021-03-11   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    <p>Genome-wide association studies identified ...   \n",
       "1    <p>Older adults experience cognitive deficits ...   \n",
       "2    <p><span><strong>data.tar.gz </strong>contains...   \n",
       "3    <p><span>data_minus_bam.tar.gz contains all fi...   \n",
       "4    <p><strong>data.tar.gz contains all files from...   \n",
       "..                                                 ...   \n",
       "124  <p>This dataset was used for this project: &qu...   \n",
       "125  <p>Dataset for the &quot;Large Scale Crowdsour...   \n",
       "126  <p>The uploaded files are in the&nbsp;fasta fo...   \n",
       "127  <p>Results of diffusion tensor imaging analysi...   \n",
       "128  <p>Results of structural and functional connec...   \n",
       "\n",
       "                                              keywords disciplines  \\\n",
       "0                                                                    \n",
       "1    peripheral, Useful Field of View, cognitive in...               \n",
       "2                                                                    \n",
       "3    long-read RNA sequencing, brain, sex, alternat...               \n",
       "4    Alzheimer's disease, neurodegeneration, cell-c...               \n",
       "..                                                 ...         ...   \n",
       "124                                                                  \n",
       "125                                                                  \n",
       "126  Horizontal gene transfer, circulating tumor DN...               \n",
       "127                                                                  \n",
       "128                                                                  \n",
       "\n",
       "    source_publication                                       related_data  \\\n",
       "0                                              <p>10.7554/eLife.57354</p>   \n",
       "1                                     <p>10.1371/journal.pone.0107808</p>   \n",
       "2                       <p>10.5281/zenodo.12548384</p><p>10.5281/zenod...   \n",
       "3                       <p>https://github.com/lasseignelab/230227_EJ_M...   \n",
       "4                                          <p>10.5281/zenodo.10211623</p>   \n",
       "..                 ...                                                ...   \n",
       "124                                                                         \n",
       "125                                                                         \n",
       "126                                                                         \n",
       "127                                                                         \n",
       "128                                                                         \n",
       "\n",
       "                         source_fulltext_url   external_rep  ...  \\\n",
       "0    https://doi.org/10.5061/dryad.rbnzs7h8z  <p>Zenodo</p>  ...   \n",
       "1        https://doi.org/10.5061/dryad.4fn70  <p>Zenodo</p>  ...   \n",
       "2    https://doi.org/10.5281/zenodo.12535061  <p>Zenodo</p>  ...   \n",
       "3    https://doi.org/10.5281/zenodo.10381745  <p>Zenodo</p>  ...   \n",
       "4    https://doi.org/10.5281/zenodo.10214497  <p>Zenodo</p>  ...   \n",
       "..                                       ...            ...  ...   \n",
       "124   https://doi.org/10.5281/zenodo.3460400  <p>Zenodo</p>  ...   \n",
       "125   https://doi.org/10.5281/zenodo.3678559  <p>Zenodo</p>  ...   \n",
       "126   https://doi.org/10.5281/zenodo.7958520  <p>Zenodo</p>  ...   \n",
       "127   https://doi.org/10.5281/zenodo.3401600  <p>Zenodo</p>  ...   \n",
       "128   https://doi.org/10.5281/zenodo.4598198  <p>Zenodo</p>  ...   \n",
       "\n",
       "    author47_lname author47_institution author48_fname author48_mname  \\\n",
       "0                                                                       \n",
       "1                                                                       \n",
       "2                                                                       \n",
       "3                                                                       \n",
       "4                                                                       \n",
       "..             ...                  ...            ...            ...   \n",
       "124                                                                     \n",
       "125                                                                     \n",
       "126                                                                     \n",
       "127                                                                     \n",
       "128                                                                     \n",
       "\n",
       "    author48_lname author48_institution author49_fname author49_mname  \\\n",
       "0                                                                       \n",
       "1                                                                       \n",
       "2                                                                       \n",
       "3                                                                       \n",
       "4                                                                       \n",
       "..             ...                  ...            ...            ...   \n",
       "124                                                                     \n",
       "125                                                                     \n",
       "126                                                                     \n",
       "127                                                                     \n",
       "128                                                                     \n",
       "\n",
       "    author49_lname author49_institution  \n",
       "0                                        \n",
       "1                                        \n",
       "2                                        \n",
       "3                                        \n",
       "4                                        \n",
       "..             ...                  ...  \n",
       "124                                      \n",
       "125                                      \n",
       "126                                      \n",
       "127                                      \n",
       "128                                      \n",
       "\n",
       "[129 rows x 209 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### BUILD OUTPUT DATAFRAME\n",
    "\n",
    "# title\n",
    "df_output = df[['title']]\n",
    "\n",
    "# orcid\n",
    "df_output = add_orcid(df1=df_input, df2=df_output)\n",
    "\n",
    "# publication_date\n",
    "df_output = add_col(df_input, \"metadata.publication_date\", df_output, \"publication_date\")\n",
    "\n",
    "# abstract\n",
    "df_output = add_col(df_input, \"metadata.description\", df_output, \"abstract\")\n",
    "df_output['abstract'] = df_output['abstract'].apply(to_html)\n",
    "\n",
    "# keywords\n",
    "df_output = add_col(df_input, \"metadata.keywords\", df_output, \"keywords\")\n",
    "df_output[\"keywords\"] = df_output[\"keywords\"].apply(list_to_string)\n",
    "\n",
    "# disciplines\n",
    "df_output[\"disciplines\"] = \"\" #make blank column, we will need to fill in the values\n",
    "\n",
    "#source_publication\n",
    "df_output[\"source_publication\"] = \"\" #make blank column, we will need to fill in the values\n",
    "\n",
    "\n",
    "# related_data\n",
    "df_output = add_related_items(df1=df_input, df2=df_output)\n",
    "\n",
    "\n",
    "\n",
    "# source_fulltext_url\n",
    "df_output = add_col(df_input, \"doi_url\", df_output, \"source_fulltext_url\")\n",
    "\n",
    "# external_rep\n",
    "df_output['external_rep'] = \"<p>Zenodo</p>\" \n",
    "\n",
    "# distribution_license and access_link\n",
    "df_output = add_license(df1=df_input, df2=df_output)\n",
    "\n",
    "# funder_info\n",
    "df_output = add_funders(df1=df_input, df2=df_output)\n",
    "\n",
    "# author info\n",
    "df_output = add_creators(df1=df_input, df2=df_output)\n",
    "\n",
    "\n",
    "\n",
    "display(df_output)\n",
    "\n",
    "df_output.to_excel('zenodo_batch_upload.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE TO .CSV\n",
    "\n",
    "# df.to_csv('zenodo_raw.csv', index=False)\n",
    "# print(df_input['title'])\n",
    "\n",
    "# df_input.to_csv('zenodo_expanded_raw.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "df_output.to_excel('zenodo_batch_upload.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'related_identifiers', 'resource_type', 'license', 'communities', 'relations', 'notes'])\n",
      "dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'contributors', 'related_identifiers', 'custom', 'resource_type', 'license', 'grants', 'relations'])\n",
      "dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'keywords', 'related_identifiers', 'locations', 'resource_type', 'license', 'communities', 'relations', 'notes'])\n"
     ]
    }
   ],
   "source": [
    "type(records)\n",
    "records.keys()\n",
    "print(len(records['hits']['hits']))\n",
    "records['hits']['hits'][0]['metadata'].keys()\n",
    "\n",
    "print(records['hits']['hits'][0]['metadata'].keys())\n",
    "print(records['hits']['hits'][1]['metadata'].keys())\n",
    "print(records['hits']['hits'][2]['metadata'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAB Pilot Center for Precision Animal Modeling (C-PAM)\n"
     ]
    }
   ],
   "source": [
    "print(records['hits']['hits'][1]['metadata']['grants'][0]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'contributors', 'related_identifiers', 'custom', 'resource_type', 'license', 'grants', 'relations'])\n",
      "3 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'contributors', 'keywords', 'related_identifiers', 'resource_type', 'license', 'grants', 'relations'])\n",
      "8 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'dates', 'language', 'custom', 'resource_type', 'license', 'grants', 'relations'])\n",
      "13 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'keywords', 'language', 'resource_type', 'license', 'grants', 'relations', 'notes'])\n",
      "44 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'contributors', 'dates', 'language', 'resource_type', 'journal', 'alternate_identifiers', 'license', 'grants', 'relations'])\n",
      "60 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'resource_type', 'license', 'grants', 'communities', 'relations', 'notes'])\n",
      "115 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'resource_type', 'license', 'grants', 'communities', 'relations'])\n",
      "118 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'resource_type', 'license', 'grants', 'communities', 'relations'])\n",
      "119 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'resource_type', 'meeting', 'license', 'grants', 'communities', 'relations'])\n",
      "120 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'resource_type', 'meeting', 'grants', 'communities', 'relations'])\n",
      "121 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'related_identifiers', 'resource_type', 'meeting', 'grants', 'communities', 'relations', 'notes'])\n",
      "122 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'version', 'resource_type', 'grants', 'communities', 'relations'])\n",
      "123 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'version', 'resource_type', 'grants', 'communities', 'relations'])\n",
      "124 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'resource_type', 'meeting', 'license', 'grants', 'communities', 'relations'])\n",
      "125 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'version', 'resource_type', 'license', 'grants', 'communities', 'relations'])\n",
      "126 dict_keys(['title', 'doi', 'publication_date', 'description', 'access_right', 'creators', 'keywords', 'version', 'language', 'resource_type', 'grants', 'relations'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(records['hits']['hits'])):\n",
    "    if 'grants' in records['hits']['hits'][i]['metadata']:\n",
    "        print( i, records['hits']['hits'][i]['metadata'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(records[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontributors\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m     20\u001b[0m     c\u001b[38;5;241m.\u001b[39mappend(records[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontributors\u001b[39m\u001b[38;5;124m'\u001b[39m][j][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m---> 22\u001b[0m contributor_counts \u001b[38;5;241m=\u001b[39m \u001b[43mCounter\u001b[49m(c)\n\u001b[0;32m     24\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m contrib \u001b[38;5;129;01min\u001b[39;00m contributor_counts\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "record_ids = []\n",
    "\n",
    "for i in range(len(records['hits']['hits'])):\n",
    "    c = []\n",
    "    contributors = ''\n",
    "    \n",
    "    record_id = records['hits']['hits'][i]['id']\n",
    "    record_ids.append(record_id)\n",
    "    if 'resource_type' in records['hits']['hits'][i]['metadata']:\n",
    "        resource_type = records['hits']['hits'][i]['metadata']['resource_type']['title']\n",
    "    else:\n",
    "        resource_type = \"none\"\n",
    "    if 'title' in records['hits']['hits'][i]['metadata']:\n",
    "        title = records['hits']['hits'][i]['metadata']['title']\n",
    "    else:\n",
    "        title = \"none\"\n",
    "    if 'contributors' in records['hits']['hits'][i]['metadata']:\n",
    "        for j in range(len(records['hits']['hits'][i]['metadata']['contributors'])):\n",
    "            c.append(records['hits']['hits'][i]['metadata']['contributors'][j]['type']) \n",
    "        \n",
    "        contributor_counts = Counter(c)\n",
    "        \n",
    "        count = 0\n",
    "        for contrib in contributor_counts.keys():\n",
    "            if (count > 0):\n",
    "                contributors += ','\n",
    "            contributors += contrib + \"=\" + str(contributor_counts[contrib])\n",
    "            count += 1\n",
    "    else:    \n",
    "        contributors = 'none'\n",
    "    \n",
    "    results.append([record_id,title,resource_type,contributors])\n",
    "\n",
    "print(record_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenodo-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
